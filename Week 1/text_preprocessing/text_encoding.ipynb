{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Encoding\n",
    "\n",
    "Since machines doesn't understand characters, words or sentence and only process nunmbers, Text data must be encoded as numbers for input or output for any machine.\n",
    "\n",
    "**Text encoding is a process to convert meaningful text into number/vector representation so as to preserve the context and relationship between words and sentences, such that a machine can understand the pattern associated in any text and can make out the context of sentences.**\n",
    "\n",
    "\n",
    "There are a lot of methods to convert text into numerical vectors. They are:\n",
    "- Index-based encoding\n",
    "- Bag of words\n",
    "- TF-IDF encoding\n",
    "- Word2Vector Encoding\n",
    "- Bert Encoding\n",
    "\n",
    "**Document Corpus:** This is the whole set of text we have, i.e, text corpus\n",
    "\n",
    "**Data Corpus:** Collection of unique words in our document corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index-based encoding\n",
    "- As the name suggest, index-based, we need to give all the unique words an index in our data corpus.\n",
    "\n",
    "- Max padding is used to make all the inputs of same length for input into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_corpus = [\"this is a good phone phone\", \n",
    "                    \"this is a bad mobile mobile\",\n",
    "                    \"she is a good good cat\", \n",
    "                    \"he has a bad temper temper\", \n",
    "                    \"this mobile phone phone is not good good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'bad', 'cat', 'good', 'has', 'he', 'is', 'mobile', 'not', 'phone', 'she', 'temper', 'this']\n"
     ]
    }
   ],
   "source": [
    "data_corpus = set()\n",
    "for sentence in document_corpus:\n",
    "    for word in sentence.split():\n",
    "        data_corpus.add(word)\n",
    "\n",
    "data_corpus = sorted(data_corpus)\n",
    "print(data_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(data_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# get the maximum length of the sentence for padding\n",
    "res = len(max(document_corpus, key = len).split())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 7, 1, 4, 10, 10, 0, 0], [13, 7, 1, 2, 8, 8, 0, 0], [11, 7, 1, 4, 4, 3, 0, 0], [6, 5, 1, 2, 12, 12, 0, 0], [13, 8, 10, 10, 7, 9, 4, 4]]\n"
     ]
    }
   ],
   "source": [
    "index_based_encoding = []\n",
    "for sentence in document_corpus:\n",
    "    sentence_encoding = []\n",
    "    split = sentence.split()\n",
    "    for i in range(res):\n",
    "        if i <= len(split) - 1:\n",
    "            sentence_encoding.append(data_corpus.index(split[i]) + 1)\n",
    "        else:\n",
    "            sentence_encoding.append(0)\n",
    "    index_based_encoding.append(sentence_encoding)\n",
    "\n",
    "print(index_based_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words(BOW)\n",
    "- BoW is another form of encoding where we use the whole data corpus to encode our sentences.\n",
    "\n",
    "- There are two kinds of BOW:\n",
    "\n",
    "**Binary BOW:** It encode 1 or 0 for wach word appearing or non-appearint in the sentece and doesn't take into consideration the frequency of the word appearning in that sentence\n",
    "\n",
    "**BOW:** It also considers the frequency of each word occuring in that sentence.\n",
    "\n",
    "**BOW completely discards the sequence information of our sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1], [1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Binary BOW\n",
    "one_hot_encoding = []\n",
    "for sentence in document_corpus:\n",
    "    sentence_encoding = []\n",
    "    split = sentence.split()\n",
    "    for word in data_corpus:\n",
    "        if word in split:\n",
    "            sentence_encoding.append(1)\n",
    "        else:\n",
    "            sentence_encoding.append(0)\n",
    "    \n",
    "    one_hot_encoding.append(sentence_encoding)\n",
    "\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 1, 3, 4, 2, 1]\n",
    "a.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1], [1, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1], [1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0], [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 0], [0, 0, 0, 2, 0, 0, 1, 1, 1, 2, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "one_hot_encoding = []\n",
    "for sentence in document_corpus:\n",
    "    sentence_encoding = []\n",
    "    split = sentence.split()\n",
    "    for word in data_corpus:\n",
    "        count = split.count(word)\n",
    "        sentence_encoding.append(count)\n",
    "    \n",
    "    one_hot_encoding.append(sentence_encoding)\n",
    "\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Encoding\n",
    "- Term frequency - Inverse document frequency\n",
    "- We give every word a relative frequency coding w.r.t the current sentence and the whole document.\n",
    "\n",
    "**Term Frequency:** is the occurence of the current word in the current sentence w.r.t the total number of words in the current sentence.\n",
    "\n",
    "**Inverse Frequency:** Log of the total number of words in the whole data corupus w.r.t the total number of sentence containing the current word.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'this': 1, 'is': 1, 'a': 1, 'good': 1, 'phone': 2}, 1: {'this': 1, 'is': 1, 'a': 1, 'bad': 1, 'mobile': 2}, 2: {'she': 1, 'is': 1, 'a': 1, 'good': 2, 'cat': 1}, 3: {'he': 1, 'has': 1, 'a': 1, 'bad': 1, 'temper': 2}, 4: {'this': 1, 'mobile': 1, 'phone': 2, 'is': 1, 'not': 1, 'good': 2}}\n"
     ]
    }
   ],
   "source": [
    "tf_dict = {}\n",
    "i = 0\n",
    "for sentence in document_corpus:\n",
    "    sentence_dict = {}\n",
    "    split = sentence.split()\n",
    "    for word in split:\n",
    "        if word not in sentence_dict.keys():\n",
    "            sentence_dict[word] = split.count(word)\n",
    "    tf_dict[i] = sentence_dict\n",
    "    i += 1\n",
    "\n",
    "print(tf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def calculate_tf(word, sentence_num):\n",
    "    row_dict = tf_dict[int(sentence_num)]\n",
    "    return row_dict[word] / sum(row_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_tf(\"phone\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(word):\n",
    "    doc_num = 0\n",
    "    for key, value in tf_dict.items():\n",
    "        if word in value.keys():\n",
    "            doc_num += 1\n",
    "    print(doc_num)\n",
    "    print(len(data_corpus))\n",
    "    return math.log(len(data_corpus) / doc_num + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0149030205422647"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_idf(\"phone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(word, sentence_num):\n",
    "    tf = calculate_tf(word, sentence_num)\n",
    "    idf = calculate_idf(word)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6716343401807549"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf('phone', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24115, 0, 0, 0.279, 0, 0, 0.24115, 0, 0, 0.67163, 0, 0, 0.279], [0.24115, 0.33582, 0, 0, 0, 0, 0.24115, 0.67163, 0, 0, 0, 0, 0.279], [0.24115, 0, 0.43984, 0.55799, 0, 0, 0.24115, 0, 0, 0, 0.43984, 0, 0], [0.24115, 0.33582, 0, 0, 0.43984, 0.43984, 0, 0, 0, 0, 0, 0.87969, 0], [0, 0, 0, 0.41849, 0, 0, 0.18086, 0.25186, 0.32988, 0.50373, 0, 0, 0.20925]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_encoding = []\n",
    "for i in range(len(document_corpus)):\n",
    "    sentence = document_corpus[i]\n",
    "    split = sentence.split()\n",
    "    sentence_encoding = []\n",
    "    for word in data_corpus:\n",
    "        if word in split:\n",
    "            sentence_encoding.append(tf_idf(word, i))\n",
    "        else:\n",
    "            sentence_encoding.append(0)\n",
    "    tf_idf_encoding.append(sentence_encoding)\n",
    "\n",
    "print(tf_idf_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf_encoding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Library Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'cat' 'good' 'has' 'he' 'is' 'mobile' 'not' 'phone' 'she' 'temper'\n",
      " 'this']\n",
      "[[0 0 1 0 0 1 0 0 2 0 0 1]\n",
      " [1 0 0 0 0 1 2 0 0 0 0 1]\n",
      " [0 1 2 0 0 1 0 0 0 1 0 0]\n",
      " [1 0 0 1 1 0 0 0 0 0 2 0]\n",
      " [0 0 2 0 0 1 1 1 2 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(document_corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'cat' 'good' 'has' 'he' 'is' 'mobile' 'not' 'phone' 'she' 'temper'\n",
      " 'this']\n",
      "[[0.         0.         0.34273991 0.         0.         0.28832362\n",
      "  0.         0.         0.82578944 0.         0.         0.34273991]\n",
      " [0.4023674  0.         0.         0.         0.         0.28097242\n",
      "  0.80473481 0.         0.         0.         0.         0.33400129]\n",
      " [0.         0.49317635 0.6605719  0.         0.         0.27784695\n",
      "  0.         0.         0.         0.49317635 0.         0.        ]\n",
      " [0.31283963 0.         0.         0.38775666 0.38775666 0.\n",
      "  0.         0.         0.         0.         0.77551332 0.        ]\n",
      " [0.         0.         0.51309679 0.         0.         0.2158166\n",
      "  0.30906082 0.38307292 0.61812163 0.         0.         0.2565484 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(document_corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_corpus = [\"this is a good phone phone\", \n",
    "                    \"this is a bad mobile mobile\",\n",
    "                    \"she is a good good cat\", \n",
    "                    \"he has a bad temper temper\", \n",
    "                    \"this mobile phone phone is not good good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad' 'bad mobile' 'bad temper' 'cat' 'good' 'good cat' 'good good'\n",
      " 'good phone' 'has' 'has bad' 'he' 'he has' 'is' 'is bad' 'is good'\n",
      " 'is not' 'mobile' 'mobile mobile' 'mobile phone' 'not' 'not good' 'phone'\n",
      " 'phone is' 'phone phone' 'she' 'she is' 'temper' 'temper temper' 'this'\n",
      " 'this is' 'this mobile']\n",
      "[[0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 2 0 1 0 0 0 0 1 1 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 2 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 1 2 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0]\n",
      " [0 0 0 0 2 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 2 1 1 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(document_corpus)\n",
    "print(cv.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
